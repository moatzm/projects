{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bab7dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, EasyEnsembleClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.combine import SMOTEENN\n",
    "from collections import Counter\n",
    "# Create the ANN model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping  # Import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a7785cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\moatz\\Desktop\\rental_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "065f2f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['return_date'] = pd.to_datetime(df['return_date'])\n",
    "df['rental_date'] = pd.to_datetime(df['rental_date'])\n",
    "df['rental_length_days']=df['return_date']-df['rental_date'] \n",
    "df['rental_length_days']=df['return_date']-df['rental_date'] \n",
    "df['rental_length_days']=df['rental_length_days'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15e8d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"deleted_scenes\"] =  np.where(df[\"special_features\"].str.contains(\"Deleted Scenes\"), 1, 0)\n",
    "# Add dummy for behind the scenes\n",
    "df[\"behind_the_scenes\"] =  np.where(df[\"special_features\"].str.contains(\"Behind the Scenes\"), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0230be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['rental_date', 'return_date', 'special_features'], axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bd97e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rental_rate</th>\n",
       "      <th>length</th>\n",
       "      <th>replacement_cost</th>\n",
       "      <th>NC-17</th>\n",
       "      <th>PG</th>\n",
       "      <th>PG-13</th>\n",
       "      <th>R</th>\n",
       "      <th>amount_2</th>\n",
       "      <th>length_2</th>\n",
       "      <th>rental_rate_2</th>\n",
       "      <th>rental_length_days</th>\n",
       "      <th>deleted_scenes</th>\n",
       "      <th>behind_the_scenes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.99</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>126.0</td>\n",
       "      <td>16.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.9401</td>\n",
       "      <td>15876.0</td>\n",
       "      <td>8.9401</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.99</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>126.0</td>\n",
       "      <td>16.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.9401</td>\n",
       "      <td>15876.0</td>\n",
       "      <td>8.9401</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.99</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>126.0</td>\n",
       "      <td>16.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.9401</td>\n",
       "      <td>15876.0</td>\n",
       "      <td>8.9401</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.99</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>126.0</td>\n",
       "      <td>16.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.9401</td>\n",
       "      <td>15876.0</td>\n",
       "      <td>8.9401</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.99</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>126.0</td>\n",
       "      <td>16.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.9401</td>\n",
       "      <td>15876.0</td>\n",
       "      <td>8.9401</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15856</th>\n",
       "      <td>6.99</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>4.99</td>\n",
       "      <td>88.0</td>\n",
       "      <td>11.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>48.8601</td>\n",
       "      <td>7744.0</td>\n",
       "      <td>24.9001</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15857</th>\n",
       "      <td>4.99</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>4.99</td>\n",
       "      <td>88.0</td>\n",
       "      <td>11.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.9001</td>\n",
       "      <td>7744.0</td>\n",
       "      <td>24.9001</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15858</th>\n",
       "      <td>8.99</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>4.99</td>\n",
       "      <td>88.0</td>\n",
       "      <td>11.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>80.8201</td>\n",
       "      <td>7744.0</td>\n",
       "      <td>24.9001</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15859</th>\n",
       "      <td>7.99</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>4.99</td>\n",
       "      <td>88.0</td>\n",
       "      <td>11.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63.8401</td>\n",
       "      <td>7744.0</td>\n",
       "      <td>24.9001</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15860</th>\n",
       "      <td>5.99</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>4.99</td>\n",
       "      <td>88.0</td>\n",
       "      <td>11.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.8801</td>\n",
       "      <td>7744.0</td>\n",
       "      <td>24.9001</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15861 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       amount  release_year  rental_rate  length  replacement_cost  NC-17  PG  \\\n",
       "0        2.99        2005.0         2.99   126.0             16.99      0   0   \n",
       "1        2.99        2005.0         2.99   126.0             16.99      0   0   \n",
       "2        2.99        2005.0         2.99   126.0             16.99      0   0   \n",
       "3        2.99        2005.0         2.99   126.0             16.99      0   0   \n",
       "4        2.99        2005.0         2.99   126.0             16.99      0   0   \n",
       "...       ...           ...          ...     ...               ...    ...  ..   \n",
       "15856    6.99        2009.0         4.99    88.0             11.99      0   0   \n",
       "15857    4.99        2009.0         4.99    88.0             11.99      0   0   \n",
       "15858    8.99        2009.0         4.99    88.0             11.99      0   0   \n",
       "15859    7.99        2009.0         4.99    88.0             11.99      0   0   \n",
       "15860    5.99        2009.0         4.99    88.0             11.99      0   0   \n",
       "\n",
       "       PG-13  R  amount_2  length_2  rental_rate_2  rental_length_days  \\\n",
       "0          0  1    8.9401   15876.0         8.9401                   3   \n",
       "1          0  1    8.9401   15876.0         8.9401                   2   \n",
       "2          0  1    8.9401   15876.0         8.9401                   7   \n",
       "3          0  1    8.9401   15876.0         8.9401                   2   \n",
       "4          0  1    8.9401   15876.0         8.9401                   4   \n",
       "...      ... ..       ...       ...            ...                 ...   \n",
       "15856      0  1   48.8601    7744.0        24.9001                   6   \n",
       "15857      0  1   24.9001    7744.0        24.9001                   4   \n",
       "15858      0  1   80.8201    7744.0        24.9001                   9   \n",
       "15859      0  1   63.8401    7744.0        24.9001                   8   \n",
       "15860      0  1   35.8801    7744.0        24.9001                   6   \n",
       "\n",
       "       deleted_scenes  behind_the_scenes  \n",
       "0                   0                  1  \n",
       "1                   0                  1  \n",
       "2                   0                  1  \n",
       "3                   0                  1  \n",
       "4                   0                  1  \n",
       "...               ...                ...  \n",
       "15856               1                  1  \n",
       "15857               1                  1  \n",
       "15858               1                  1  \n",
       "15859               1                  1  \n",
       "15860               1                  1  \n",
       "\n",
       "[15861 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f905133",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['rental_length_days'],axis=1)\n",
    "y=df['rental_length_days']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca3e8357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the scaling module\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "inputs_scaled=scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acd9d10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the module for the split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the variables with an 80-20 split and some random state\n",
    "# To have the same split as mine, use random_state = 365\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs_scaled, y, test_size=0.2, random_state=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2338ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.916947941357664\n",
      "R-squared: 0.5979775530635872\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)  # Mean Squared Error\n",
    "r2 = r2_score(y_test, y_pred)  # R-squared score\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22bd0760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.039200443841836\n",
      "R-squared: 0.7189513255949491\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "604db248",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moatz\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\moatz\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 6.0816 - mae: 1.8031 - mse: 5.2719 - val_loss: 3.1678 - val_mae: 1.3316 - val_mse: 2.7066\n",
      "Epoch 2/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 3.1696 - mae: 1.3624 - mse: 2.7587 - val_loss: 2.7622 - val_mae: 1.2899 - val_mse: 2.4856\n",
      "Epoch 3/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 2.8932 - mae: 1.3320 - mse: 2.6437 - val_loss: 2.5906 - val_mae: 1.2637 - val_mse: 2.4087\n",
      "Epoch 4/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - loss: 2.6463 - mae: 1.2909 - mse: 2.4788 - val_loss: 2.6013 - val_mae: 1.2789 - val_mse: 2.4657\n",
      "Epoch 5/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 2.6377 - mae: 1.3049 - mse: 2.5099 - val_loss: 2.5067 - val_mae: 1.2638 - val_mse: 2.3977\n",
      "Epoch 6/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 2.6099 - mae: 1.3038 - mse: 2.5043 - val_loss: 2.5844 - val_mae: 1.2924 - val_mse: 2.4890\n",
      "Epoch 7/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 2.6222 - mae: 1.3062 - mse: 2.5297 - val_loss: 2.5742 - val_mae: 1.2795 - val_mse: 2.4867\n",
      "Epoch 8/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 2.5577 - mae: 1.2964 - mse: 2.4736 - val_loss: 2.5061 - val_mae: 1.2673 - val_mse: 2.4242\n",
      "Epoch 9/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 2.5719 - mae: 1.2914 - mse: 2.4915 - val_loss: 2.6424 - val_mae: 1.3086 - val_mse: 2.5681\n",
      "Epoch 10/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 2.5167 - mae: 1.2849 - mse: 2.4397 - val_loss: 2.4910 - val_mae: 1.2689 - val_mse: 2.4154\n",
      "Epoch 11/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 2.5291 - mae: 1.2875 - mse: 2.4535 - val_loss: 2.6083 - val_mae: 1.3043 - val_mse: 2.5347\n",
      "Epoch 12/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 2.5385 - mae: 1.2809 - mse: 2.4654 - val_loss: 2.5553 - val_mae: 1.2878 - val_mse: 2.4831\n",
      "Epoch 13/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 2.4648 - mae: 1.2676 - mse: 2.3933 - val_loss: 2.4949 - val_mae: 1.2661 - val_mse: 2.4218\n",
      "Epoch 14/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 2.5412 - mae: 1.2878 - mse: 2.4696 - val_loss: 2.5022 - val_mae: 1.2747 - val_mse: 2.4328\n",
      "Epoch 15/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 2.5044 - mae: 1.2750 - mse: 2.4326 - val_loss: 2.5001 - val_mae: 1.2704 - val_mse: 2.4293\n",
      "Epoch 16/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 2.4901 - mae: 1.2702 - mse: 2.4179 - val_loss: 2.4984 - val_mae: 1.2652 - val_mse: 2.4269\n",
      "Epoch 17/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 2.4856 - mae: 1.2739 - mse: 2.4151 - val_loss: 2.4922 - val_mae: 1.2706 - val_mse: 2.4208\n",
      "Epoch 18/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 2.4922 - mae: 1.2721 - mse: 2.4201 - val_loss: 2.4632 - val_mae: 1.2631 - val_mse: 2.3914\n",
      "Epoch 19/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 2.4958 - mae: 1.2732 - mse: 2.4225 - val_loss: 2.5867 - val_mae: 1.2848 - val_mse: 2.5145\n",
      "Epoch 20/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 2.4274 - mae: 1.2507 - mse: 2.3549 - val_loss: 2.4876 - val_mae: 1.2665 - val_mse: 2.4152\n",
      "Epoch 21/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - loss: 2.5010 - mae: 1.2743 - mse: 2.4276 - val_loss: 2.4948 - val_mae: 1.2700 - val_mse: 2.4216\n",
      "Epoch 22/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 2.5126 - mae: 1.2769 - mse: 2.4393 - val_loss: 2.5330 - val_mae: 1.2709 - val_mse: 2.4595\n",
      "Epoch 23/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 2.4551 - mae: 1.2590 - mse: 2.3818 - val_loss: 2.5739 - val_mae: 1.2841 - val_mse: 2.5006\n",
      "Epoch 24/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 2.4444 - mae: 1.2573 - mse: 2.3706 - val_loss: 2.4834 - val_mae: 1.2632 - val_mse: 2.4097\n",
      "Epoch 25/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 2.4243 - mae: 1.2533 - mse: 2.3503 - val_loss: 2.5016 - val_mae: 1.2687 - val_mse: 2.4268\n",
      "Epoch 26/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 2.4653 - mae: 1.2608 - mse: 2.3912 - val_loss: 2.5009 - val_mae: 1.2681 - val_mse: 2.4275\n",
      "Epoch 27/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - loss: 2.4058 - mae: 1.2455 - mse: 2.3322 - val_loss: 2.5079 - val_mae: 1.2774 - val_mse: 2.4341\n",
      "Epoch 28/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 2.5145 - mae: 1.2792 - mse: 2.4401 - val_loss: 2.4823 - val_mae: 1.2656 - val_mse: 2.4065\n",
      "Epoch 29/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - loss: 2.4899 - mae: 1.2743 - mse: 2.4139 - val_loss: 2.6244 - val_mae: 1.3133 - val_mse: 2.5511\n",
      "Epoch 30/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - loss: 2.4366 - mae: 1.2563 - mse: 2.3625 - val_loss: 2.6327 - val_mae: 1.3109 - val_mse: 2.5588\n",
      "Epoch 31/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 2.4700 - mae: 1.2681 - mse: 2.3961 - val_loss: 2.6417 - val_mae: 1.3178 - val_mse: 2.5685\n",
      "Epoch 32/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - loss: 2.4294 - mae: 1.2468 - mse: 2.3559 - val_loss: 2.4769 - val_mae: 1.2694 - val_mse: 2.4050\n",
      "Epoch 33/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 2.4924 - mae: 1.2697 - mse: 2.4201 - val_loss: 2.5376 - val_mae: 1.2919 - val_mse: 2.4666\n",
      "Epoch 34/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 2.4470 - mae: 1.2532 - mse: 2.3750 - val_loss: 2.5361 - val_mae: 1.2818 - val_mse: 2.4636\n",
      "Epoch 35/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - loss: 2.4678 - mae: 1.2649 - mse: 2.3962 - val_loss: 2.6277 - val_mae: 1.3133 - val_mse: 2.5562\n",
      "Epoch 36/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 2.5012 - mae: 1.2707 - mse: 2.4293 - val_loss: 2.5288 - val_mae: 1.2808 - val_mse: 2.4579\n",
      "Epoch 37/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 2.4115 - mae: 1.2449 - mse: 2.3402 - val_loss: 2.4840 - val_mae: 1.2691 - val_mse: 2.4116\n",
      "Epoch 38/5000\n",
      "\u001b[1m2538/2538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 2.4153 - mae: 1.2479 - mse: 2.3429 - val_loss: 2.6336 - val_mae: 1.2964 - val_mse: 2.5612\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6862 - mae: 1.3128 - mse: 2.6138\n",
      "Mean Squared Error: [2.6349871158599854, 1.3009535074234009, 2.5626537799835205]\n",
      "Predicted Sales: [2.2127721 2.363192  5.428241  ... 5.7364078 2.213985  6.537085 ]\n",
      "Actual Sales: [3 0 4 ... 8 3 7]\n"
     ]
    }
   ],
   "source": [
    "# Create the ANN model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping  # Import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer and hidden layers\n",
    "model = Sequential()\n",
    "model.add(Dense(123, input_shape=(x_train.shape[1],), activation=\"relu\",kernel_regularizer=regularizers.l2(0.01)))\n",
    "BatchNormalization(),\n",
    "model.add(Dense(56, activation=\"relu\",kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(16, activation=\"relu\"))  \n",
    "model.add(Dense(8, activation=\"relu\"))   \n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))  # Single output value (sales prediction)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae','mse'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=5000,\n",
    "    batch_size=4,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Evaluate model performance (on test set)\n",
    "mse = model.evaluate(x_test, y_test)  # Corrected variable name\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Print predictions and actual values\n",
    "print(\"Predicted Sales:\", y_pred.flatten())\n",
    "print(\"Actual Sales:\", y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f6aaa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.6468073129653931\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5762c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted Sales:\", y_pred.flatten())\n",
    "print(\"Actual Sales:\", y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "290627b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Sales</th>\n",
       "      <th>Actual Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.957545</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.417367</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.586077</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.527959</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.933076</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3168</th>\n",
       "      <td>2.390293</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>7.357182</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>4.618639</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>4.280032</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>6.348597</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3173 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Predicted Sales  Actual Sales\n",
       "0            2.957545             3\n",
       "1            3.417367             0\n",
       "2            4.586077             4\n",
       "3            2.527959             6\n",
       "4            7.933076             8\n",
       "...               ...           ...\n",
       "3168         2.390293             1\n",
       "3169         7.357182             7\n",
       "3170         4.618639             8\n",
       "3171         4.280032             3\n",
       "3172         6.348597             7\n",
       "\n",
       "[3173 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Predicted Sales': y_pred.flatten(),'Actual Sales':y_test.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d8f6bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.39\n",
      "R² Score: 0.6701204180717468\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"R² Score: {r2:}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d4980cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(r'C:\\Users\\moatz\\Desktop\\New folder/model_pickle.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3053bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(r'C:\\Users\\moatz\\Desktop\\New folder/model_pickle.pkl','rb') as file:\n",
    "    mp = pickle.load(file)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
